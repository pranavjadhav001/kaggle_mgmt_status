{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:01:58.259808Z",
     "iopub.status.busy": "2021-10-06T17:01:58.258294Z",
     "iopub.status.idle": "2021-10-06T17:02:06.218043Z",
     "shell.execute_reply": "2021-10-06T17:02:06.216757Z",
     "shell.execute_reply.started": "2021-10-06T16:46:56.023534Z"
    },
    "papermill": {
     "duration": 7.980091,
     "end_time": "2021-10-06T17:02:06.218239",
     "exception": false,
     "start_time": "2021-10-06T17:01:58.238148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting classification-models-3D\r\n",
      "  Downloading classification_models_3D-1.0.2-py3-none-any.whl (45 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 45 kB 1.5 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: keras>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from classification-models-3D) (2.4.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from classification-models-3D) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras>=2.2.0->classification-models-3D) (2.10.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras>=2.2.0->classification-models-3D) (1.6.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras>=2.2.0->classification-models-3D) (5.4.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras>=2.2.0->classification-models-3D) (1.15.0)\r\n",
      "Installing collected packages: classification-models-3D\r\n",
      "Successfully installed classification-models-3D-1.0.2\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install classification-models-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:06.284555Z",
     "iopub.status.busy": "2021-10-06T17:02:06.283696Z",
     "iopub.status.idle": "2021-10-06T17:02:06.285937Z",
     "shell.execute_reply": "2021-10-06T17:02:06.285249Z",
     "shell.execute_reply.started": "2021-08-28T07:43:15.389872Z"
    },
    "papermill": {
     "duration": 0.038253,
     "end_time": "2021-10-06T17:02:06.286092",
     "exception": false,
     "start_time": "2021-10-06T17:02:06.247839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install efficientnet-3D keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:06.348681Z",
     "iopub.status.busy": "2021-10-06T17:02:06.347936Z",
     "iopub.status.idle": "2021-10-06T17:02:12.912037Z",
     "shell.execute_reply": "2021-10-06T17:02:12.911119Z",
     "shell.execute_reply.started": "2021-10-06T16:47:02.050163Z"
    },
    "papermill": {
     "duration": 6.599632,
     "end_time": "2021-10-06T17:02:12.912182",
     "exception": false,
     "start_time": "2021-10-06T17:02:06.312550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_applications\r\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 50 kB 2.8 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications) (1.15.0)\r\n",
      "Installing collected packages: keras-applications\r\n",
      "Successfully installed keras-applications-1.0.8\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:12.953334Z",
     "iopub.status.busy": "2021-10-06T17:02:12.952570Z",
     "iopub.status.idle": "2021-10-06T17:02:17.516600Z",
     "shell.execute_reply": "2021-10-06T17:02:17.516057Z",
     "shell.execute_reply.started": "2021-10-06T16:47:08.854119Z"
    },
    "papermill": {
     "duration": 4.586736,
     "end_time": "2021-10-06T17:02:17.516731",
     "exception": false,
     "start_time": "2021-10-06T17:02:12.929995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import pandas\n",
    "from tensorflow.keras import layers\n",
    "from classification_models_3D.keras import Classifiers\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "#random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:17.559840Z",
     "iopub.status.busy": "2021-10-06T17:02:17.559031Z",
     "iopub.status.idle": "2021-10-06T17:02:17.561862Z",
     "shell.execute_reply": "2021-10-06T17:02:17.561431Z",
     "shell.execute_reply.started": "2021-10-06T16:47:13.457562Z"
    },
    "papermill": {
     "duration": 0.027064,
     "end_time": "2021-10-06T17:02:17.561972",
     "exception": false,
     "start_time": "2021-10-06T17:02:17.534908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_slices(df,base_dir): \n",
    "    all_paths = []\n",
    "    for i in list(df['folder_id']):\n",
    "        i = os.path.join(base_dir,i)\n",
    "        all_paths.append(len(glob.glob(i+'/flair/*')))\n",
    "    return all_paths\n",
    "\n",
    "def split_train_test(slices_list,folders_list,label_list,split_ratio=0.1):\n",
    "    test_size = int(len(slices_list)*split_ratio)\n",
    "    test_slices_list = slices_list[:test_size]\n",
    "    test_folders_list = folders_list[:test_size]\n",
    "    test_label_list = label_list[:test_size]\n",
    "    train_slices_list = slices_list[test_size:]\n",
    "    train_folders_list = folders_list[test_size:]\n",
    "    train_label_list = label_list[test_size:]\n",
    "    return train_slices_list,train_folders_list,train_label_list,test_slices_list,test_folders_list,test_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:17.601206Z",
     "iopub.status.busy": "2021-10-06T17:02:17.600677Z",
     "iopub.status.idle": "2021-10-06T17:02:17.617730Z",
     "shell.execute_reply": "2021-10-06T17:02:17.617288Z",
     "shell.execute_reply.started": "2021-10-06T16:47:19.013105Z"
    },
    "papermill": {
     "duration": 0.0381,
     "end_time": "2021-10-06T17:02:17.617843",
     "exception": false,
     "start_time": "2021-10-06T17:02:17.579743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/rsnasubmissionresult/result.csv',dtype='str')\n",
    "base_dir = '../input/classify-tumor-best/DATATUMORONLY_TRAIN/train'\n",
    "#slices_list = np.array(get_all_slices(df,base_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:17.657432Z",
     "iopub.status.busy": "2021-10-06T17:02:17.656710Z",
     "iopub.status.idle": "2021-10-06T17:02:17.658996Z",
     "shell.execute_reply": "2021-10-06T17:02:17.659525Z",
     "shell.execute_reply.started": "2021-10-06T16:47:20.446679Z"
    },
    "papermill": {
     "duration": 0.024583,
     "end_time": "2021-10-06T17:02:17.659663",
     "exception": false,
     "start_time": "2021-10-06T17:02:17.635080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df.iloc[:525,:]\n",
    "test_df = df.iloc[526:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:17.706775Z",
     "iopub.status.busy": "2021-10-06T17:02:17.706203Z",
     "iopub.status.idle": "2021-10-06T17:02:20.662627Z",
     "shell.execute_reply": "2021-10-06T17:02:20.662108Z",
     "shell.execute_reply.started": "2021-10-06T16:47:21.989863Z"
    },
    "papermill": {
     "duration": 2.985552,
     "end_time": "2021-10-06T17:02:20.662770",
     "exception": false,
     "start_time": "2021-10-06T17:02:17.677218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_slices_list = np.array(get_all_slices(train_df,base_dir))\n",
    "test_slices_list = np.array(get_all_slices(test_df,base_dir))\n",
    "#slices_list = np.array(list(df['flair']))\n",
    "train_folders_list = np.array(list(train_df['folder_id']))\n",
    "test_folders_list = np.array(list(test_df['folder_id']))\n",
    "train_label_list = np.array(list(train_df['MGMT_value']))\n",
    "test_label_list = np.array(list(test_df['MGMT_value']))\n",
    "indexes = np.where((train_slices_list > 0 )&(train_slices_list < 50))\n",
    "train_slices_list = np.take(train_slices_list,indexes)[0]\n",
    "train_folders_list = np.take(train_folders_list,indexes)[0]\n",
    "train_label_list = np.take(train_label_list,indexes)[0]\n",
    "indexes = np.where((test_slices_list > 0 )&(test_slices_list < 50))\n",
    "test_slices_list = np.take(test_slices_list,indexes)[0]\n",
    "test_folders_list = np.take(test_folders_list,indexes)[0]\n",
    "test_label_list = np.take(test_label_list,indexes)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:20.702361Z",
     "iopub.status.busy": "2021-10-06T17:02:20.701605Z",
     "iopub.status.idle": "2021-10-06T17:02:20.704235Z",
     "shell.execute_reply": "2021-10-06T17:02:20.703844Z",
     "shell.execute_reply.started": "2021-09-15T05:32:26.881822Z"
    },
    "papermill": {
     "duration": 0.023545,
     "end_time": "2021-10-06T17:02:20.704339",
     "exception": false,
     "start_time": "2021-10-06T17:02:20.680794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../input/rsnasubmissionresult/result.csv',dtype='str')\n",
    "# base_dir = '../input/classify-tumor-best/DATATUMORONLY_TRAIN/train'\n",
    "# slices_list = np.array(get_all_slices(df,base_dir))\n",
    "# #slices_list = np.array(list(df['flair']))\n",
    "# folders_list = np.array(list(df['folder_id']))\n",
    "# label_list = np.array(list(df['MGMT_value']))\n",
    "# indexes = np.where((slices_list > 0 )&(slices_list < 50))\n",
    "# slices_list = np.take(slices_list,indexes)[0]\n",
    "# folders_list = np.take(folders_list,indexes)[0]\n",
    "# label_list = np.take(label_list,indexes)[0]\n",
    "# shuffler = np.random.permutation(len(slices_list))\n",
    "# slices_list = slices_list[shuffler]\n",
    "# folders_list = folders_list[shuffler]\n",
    "# label_list = label_list[shuffler]\n",
    "# train_slices_list,train_folders_list,train_label_list,\\\n",
    "# test_slices_list,test_folders_list,test_label_list = split_train_test(slices_list,folders_list,label_list,split_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:20.761879Z",
     "iopub.status.busy": "2021-10-06T17:02:20.761102Z",
     "iopub.status.idle": "2021-10-06T17:02:20.763253Z",
     "shell.execute_reply": "2021-10-06T17:02:20.763674Z",
     "shell.execute_reply.started": "2021-10-06T16:47:25.355143Z"
    },
    "papermill": {
     "duration": 0.04173,
     "end_time": "2021-10-06T17:02:20.763799",
     "exception": false,
     "start_time": "2021-10-06T17:02:20.722069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,slices_list,folders_list,label_list,width=256,height=256,batch_size=16,shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.base_dir = '../input/classify-tumor-best/DATATUMORONLY_TRAIN/train'\n",
    "        self.width = width\n",
    "        self.crop_length = 224\n",
    "        self.height = height\n",
    "        self.tolerance = 5\n",
    "        self.shuffle = shuffle\n",
    "        self.intial_slices_list = slices_list\n",
    "        self.intial_folders_list = folders_list\n",
    "        self.intial_label_list = label_list\n",
    "        #print(len(self.slices_list))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        print('epoch ended')\n",
    "        self.slices_list = self.intial_slices_list.copy()\n",
    "        self.folders_list = self.intial_folders_list.copy()\n",
    "        self.label_list = self.intial_label_list.copy()\n",
    "        if self.shuffle:\n",
    "            shuffler = np.random.permutation(len(self.slices_list))\n",
    "            self.slices_list = self.slices_list[shuffler]\n",
    "            self.folders_list = self.folders_list[shuffler]\n",
    "            self.label_list = self.label_list[shuffler]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.intial_slices_list)\n",
    "    \n",
    "    def __getitem__(self,user_index):\n",
    "        start =time.time()\n",
    "        index = self.slices_list[0]\n",
    "        #print(len(self.slices_list))\n",
    "        labels = []\n",
    "        indexes = np.where((self.slices_list >= index-self.tolerance) &(self.slices_list <= index+self.tolerance))\n",
    "        tol_slice= np.take(self.slices_list, indexes)[0]\n",
    "        tol_folder= np.take(self.folders_list, indexes)[0]\n",
    "        random_indexes = np.random.choice(indexes[0], size=min(self.batch_size,len(tol_folder)),replace=False)\n",
    "        random_folder = np.take(self.folders_list,random_indexes)\n",
    "        random_slices = np.take(self.slices_list,random_indexes)\n",
    "        random_labels = np.take(self.label_list,random_indexes)\n",
    "        self.folders_list = np.delete(self.folders_list,random_indexes)\n",
    "        self.slices_list = np.delete(self.slices_list,random_indexes)\n",
    "        self.label_list = np.delete(self.label_list,random_indexes)\n",
    "        #print(len(self.slices_list))\n",
    "        self.max_depth = random_slices.max()\n",
    "        #print(random_folder)\n",
    "        batch_x = self.__data_gen_batch(random_folder)\n",
    "        #for i in random_folder:\n",
    "        #    labels.append(int(self.label_list[np.where(self.folders_list == i)[0]][0]))\n",
    "        #print(labels)\n",
    "        return preprocess_input(batch_x),self.one_hot_encoder(random_labels.astype(np.int8))\n",
    "    \n",
    "    def one_hot_encoder(self,y):\n",
    "        b = np.zeros((len(y), 2))\n",
    "        b[np.arange(len(y)),y] = 1\n",
    "        return b\n",
    "    \n",
    "    def get_max_len(self,batch,min_depth=50):\n",
    "        max_len = 0\n",
    "        for patient_id in batch['folder_id']:\n",
    "            #print(os.path.join(self.base_dir,patient_id,'flair/*'))\n",
    "            length = len(glob.glob(os.path.join(self.base_dir,patient_id,'flair/*')))\n",
    "            if length > max_len:\n",
    "                max_len = length\n",
    "        if max_len < min_depth:\n",
    "            max_len = min_depth\n",
    "        return max_len\n",
    "\n",
    "    def __data_gen_image(self,folder_name):\n",
    "        flair_path = glob.glob(os.path.join(self.base_dir,folder_name,'flair/*'))\n",
    "        flair_path = sorted(flair_path,key=lambda x:x.split('-')[-1].split('.')[-2].zfill(3))\n",
    "        all_images = []\n",
    "        all_images = np.zeros(shape=(self.max_depth,self.height,self.height,1),dtype=np.float64)\n",
    "        for i,img_path in enumerate(flair_path):\n",
    "            img = image.load_img(img_path,target_size=(self.height,self.width),color_mode='grayscale')\n",
    "            img = image.img_to_array(img)\n",
    "            all_images[i,] = img\n",
    "        return np.transpose(all_images,(1,2,0,3))\n",
    "\n",
    "    def __data_gen_batch(self,folder_names):\n",
    "        batch_data = np.empty(shape=(len(folder_names),self.height,self.width,self.max_depth,1))\n",
    "        for i,patient_id in enumerate(folder_names):\n",
    "            batch_data[i,] = self.__data_gen_image(patient_id)\n",
    "        return batch_data\n",
    "    \n",
    "    def crop(self,image,crop_length=224):\n",
    "        img_height ,img_width = image.shape[:2]\n",
    "        start_y = (img_height - self.crop_length) // 2\n",
    "        start_x = (img_width - self.crop_length) // 2\n",
    "        cropped_image=image[start_y:(img_height - start_y), start_x:(img_width - start_x), :]\n",
    "        return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:20.803532Z",
     "iopub.status.busy": "2021-10-06T17:02:20.802955Z",
     "iopub.status.idle": "2021-10-06T17:02:20.805986Z",
     "shell.execute_reply": "2021-10-06T17:02:20.806566Z",
     "shell.execute_reply.started": "2021-10-06T16:47:28.506858Z"
    },
    "papermill": {
     "duration": 0.025456,
     "end_time": "2021-10-06T17:02:20.806717",
     "exception": false,
     "start_time": "2021-10-06T17:02:20.781261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch ended\n",
      "epoch ended\n"
     ]
    }
   ],
   "source": [
    "train_datagen = DataGenerator(train_slices_list,train_folders_list,train_label_list,batch_size=5,height=224,width=224,shuffle=True)\n",
    "test_datagen = DataGenerator(test_slices_list,test_folders_list,test_label_list,batch_size=1,height=224,width=224,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:20.848219Z",
     "iopub.status.busy": "2021-10-06T17:02:20.847502Z",
     "iopub.status.idle": "2021-10-06T17:02:20.850160Z",
     "shell.execute_reply": "2021-10-06T17:02:20.849726Z",
     "shell.execute_reply.started": "2021-09-16T17:09:27.567834Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.024142,
     "end_time": "2021-10-06T17:02:20.850268",
     "exception": false,
     "start_time": "2021-10-06T17:02:20.826126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for _ in range(3):\n",
    "#     print('new epoch')\n",
    "#     for i in range(len(test_datagen)-1):\n",
    "#         x,y = test_datagen[i]\n",
    "#         print(i,x.shape,len(test_datagen.slices_list))\n",
    "#     test_datagen.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:20.891872Z",
     "iopub.status.busy": "2021-10-06T17:02:20.891071Z",
     "iopub.status.idle": "2021-10-06T17:02:20.893573Z",
     "shell.execute_reply": "2021-10-06T17:02:20.893975Z"
    },
    "papermill": {
     "duration": 0.024282,
     "end_time": "2021-10-06T17:02:20.894086",
     "exception": false,
     "start_time": "2021-10-06T17:02:20.869804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basemodel = efn.EfficientNetB0(input_shape=(256, 256, None, 1), weights=None)\n",
    "# x = layers.GlobalAveragePooling3D()(basemodel.output)\n",
    "# x = layers.Dense(units=128, activation=\"relu\")(x)\n",
    "# x = layers.Dropout(0.1)(x)\n",
    "# outputs = layers.Dense(units=2, activation=\"softmax\")(x)\n",
    "# # Define the model.\n",
    "# model = keras.Model(basemodel.input, outputs, name=\"eff3dcnn\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:20.933611Z",
     "iopub.status.busy": "2021-10-06T17:02:20.933080Z",
     "iopub.status.idle": "2021-10-06T17:02:23.288328Z",
     "shell.execute_reply": "2021-10-06T17:02:23.287402Z",
     "shell.execute_reply.started": "2021-10-06T16:47:30.392028Z"
    },
    "papermill": {
     "duration": 2.376689,
     "end_time": "2021-10-06T17:02:23.288485",
     "exception": false,
     "start_time": "2021-10-06T17:02:20.911796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "model = ResNet18(input_shape=(224, 224, None, 1), weights=None,include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:23.330862Z",
     "iopub.status.busy": "2021-10-06T17:02:23.330001Z",
     "iopub.status.idle": "2021-10-06T17:02:23.394298Z",
     "shell.execute_reply": "2021-10-06T17:02:23.394943Z",
     "shell.execute_reply.started": "2021-10-06T16:47:32.820524Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.088549,
     "end_time": "2021-10-06T17:02:23.395124",
     "exception": false,
     "start_time": "2021-10-06T17:02:23.306575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet18_3d\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 224, 224, No 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 224, 224, Non 3           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d (ZeroPadding3D)  (None, 230, 230, Non 0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv3D)                  (None, 112, 112, Non 21952       zero_padding3d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 112, 112, Non 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 112, 112, Non 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPadding3D (None, 114, 114, Non 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling3D)         (None, 56, 56, None, 0           zero_padding3d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 56, 56, None, 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 56, 56, None, 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_2 (ZeroPadding3D (None, 58, 58, None, 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv3D)     (None, 56, 56, None, 110592      zero_padding3d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 56, 56, None, 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 56, 56, None, 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_3 (ZeroPadding3D (None, 58, 58, None, 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv3D)     (None, 56, 56, None, 110592      zero_padding3d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv3D)        (None, 56, 56, None, 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, None, 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 56, 56, None, 256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 56, 56, None, 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_4 (ZeroPadding3D (None, 58, 58, None, 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv3D)     (None, 56, 56, None, 110592      zero_padding3d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 56, 56, None, 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 56, 56, None, 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_5 (ZeroPadding3D (None, 58, 58, None, 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv3D)     (None, 56, 56, None, 110592      zero_padding3d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, None, 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 56, 56, None, 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 56, 56, None, 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_6 (ZeroPadding3D (None, 58, 58, None, 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv3D)     (None, 28, 28, None, 221184      zero_padding3d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 28, 28, None, 512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 28, 28, None, 0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_7 (ZeroPadding3D (None, 30, 30, None, 0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv3D)     (None, 28, 28, None, 442368      zero_padding3d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv3D)        (None, 28, 28, None, 8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, None, 0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 28, 28, None, 512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 28, 28, None, 0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_8 (ZeroPadding3D (None, 30, 30, None, 0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv3D)     (None, 28, 28, None, 442368      zero_padding3d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 28, 28, None, 512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 28, 28, None, 0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_9 (ZeroPadding3D (None, 30, 30, None, 0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv3D)     (None, 28, 28, None, 442368      zero_padding3d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, None, 0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 28, 28, None, 512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 28, 28, None, 0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_10 (ZeroPadding3 (None, 30, 30, None, 0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv3D)     (None, 14, 14, None, 884736      zero_padding3d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 14, 14, None, 1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 14, 14, None, 0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_11 (ZeroPadding3 (None, 16, 16, None, 0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv3D)     (None, 14, 14, None, 1769472     zero_padding3d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv3D)        (None, 14, 14, None, 32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, None, 0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 14, 14, None, 1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 14, 14, None, 0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_12 (ZeroPadding3 (None, 16, 16, None, 0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv3D)     (None, 14, 14, None, 1769472     zero_padding3d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 14, 14, None, 1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 14, 14, None, 0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_13 (ZeroPadding3 (None, 16, 16, None, 0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv3D)     (None, 14, 14, None, 1769472     zero_padding3d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, None, 0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 14, 14, None, 1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 14, 14, None, 0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_14 (ZeroPadding3 (None, 16, 16, None, 0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv3D)     (None, 7, 7, None, 5 3538944     zero_padding3d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 7, 7, None, 5 2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 7, 7, None, 5 0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_15 (ZeroPadding3 (None, 9, 9, None, 5 0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv3D)     (None, 7, 7, None, 5 7077888     zero_padding3d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv3D)        (None, 7, 7, None, 5 131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 7, 7, None, 5 0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 7, 7, None, 5 2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 7, 7, None, 5 0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_16 (ZeroPadding3 (None, 9, 9, None, 5 0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv3D)     (None, 7, 7, None, 5 7077888     zero_padding3d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 7, 7, None, 5 2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 7, 7, None, 5 0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding3d_17 (ZeroPadding3 (None, 9, 9, None, 5 0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv3D)     (None, 7, 7, None, 5 7077888     zero_padding3d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 7, 7, None, 5 0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 7, 7, None, 5 2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 7, 7, None, 5 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (GlobalAveragePooling3D)  (None, 512)          0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            1026        pool1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 33,171,397\n",
      "Trainable params: 33,163,459\n",
      "Non-trainable params: 7,938\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#x = layers.Dense(units=128, activation=\"relu\")(model.layers[-3].output)\n",
    "#x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(units=2, activation=\"softmax\")(model.layers[-3].output)\n",
    "# Define the model.\n",
    "new_model = keras.Model(model.input, outputs, name=\"resnet18_3d\")\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:23.479109Z",
     "iopub.status.busy": "2021-10-06T17:02:23.478262Z",
     "iopub.status.idle": "2021-10-06T17:02:23.482492Z",
     "shell.execute_reply": "2021-10-06T17:02:23.482907Z",
     "shell.execute_reply.started": "2021-10-06T16:47:37.664995Z"
    },
    "papermill": {
     "duration": 0.048789,
     "end_time": "2021-10-06T17:02:23.483038",
     "exception": false,
     "start_time": "2021-10-06T17:02:23.434249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('models')\n",
    "os.makedirs('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:23.577953Z",
     "iopub.status.busy": "2021-10-06T17:02:23.576974Z",
     "iopub.status.idle": "2021-10-06T17:02:23.992360Z",
     "shell.execute_reply": "2021-10-06T17:02:23.991701Z",
     "shell.execute_reply.started": "2021-10-06T16:47:45.397186Z"
    },
    "papermill": {
     "duration": 0.473796,
     "end_time": "2021-10-06T17:02:23.992515",
     "exception": false,
     "start_time": "2021-10-06T17:02:23.518719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"models/3d_image_classification.hdf5\", save_best_only=True,monitor=\"val_accuracy\",mode=\"max\",verbose=0)\n",
    "summary = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\",update_freq=1,histogram_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T17:02:24.034920Z",
     "iopub.status.busy": "2021-10-06T17:02:24.034318Z",
     "iopub.status.idle": "2021-10-06T19:44:10.343617Z",
     "shell.execute_reply": "2021-10-06T19:44:10.345200Z"
    },
    "papermill": {
     "duration": 9706.334341,
     "end_time": "2021-10-06T19:44:10.345451",
     "exception": false,
     "start_time": "2021-10-06T17:02:24.011110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0014 - accuracy: 0.5083epoch ended\n",
      "85/85 [==============================] - 465s 5s/step - loss: 0.9995 - accuracy: 0.5082 - val_loss: 1035.8778 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 2/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7373 - accuracy: 0.4662epoch ended\n",
      "85/85 [==============================] - 169s 2s/step - loss: 0.7372 - accuracy: 0.4661 - val_loss: 0.8375 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 3/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.4746epoch ended\n",
      "85/85 [==============================] - 114s 1s/step - loss: 0.7033 - accuracy: 0.4746 - val_loss: 2.2102 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 4/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7265 - accuracy: 0.4852epoch ended\n",
      "85/85 [==============================] - 58s 682ms/step - loss: 0.7264 - accuracy: 0.4850 - val_loss: 0.9020 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 5/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.5334epoch ended\n",
      "85/85 [==============================] - 26s 294ms/step - loss: 0.7025 - accuracy: 0.5332 - val_loss: 1.4501 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 6/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7195 - accuracy: 0.4944epoch ended\n",
      "85/85 [==============================] - 41s 485ms/step - loss: 0.7196 - accuracy: 0.4944 - val_loss: 4.3908 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 7/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7281 - accuracy: 0.5207epoch ended\n",
      "85/85 [==============================] - 36s 421ms/step - loss: 0.7280 - accuracy: 0.5208 - val_loss: 1.3549 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 8/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7002 - accuracy: 0.5234epoch ended\n",
      "85/85 [==============================] - 32s 371ms/step - loss: 0.7001 - accuracy: 0.5236 - val_loss: 1.0537 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 9/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.5471epoch ended\n",
      "85/85 [==============================] - 36s 421ms/step - loss: 0.7647 - accuracy: 0.5468 - val_loss: 1.5295 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 10/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7066 - accuracy: 0.4781epoch ended\n",
      "85/85 [==============================] - 51s 606ms/step - loss: 0.7066 - accuracy: 0.4782 - val_loss: 1.2035 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 11/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.5322epoch ended\n",
      "85/85 [==============================] - 49s 582ms/step - loss: 0.7035 - accuracy: 0.5325 - val_loss: 1.4816 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 12/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.5641epoch ended\n",
      "85/85 [==============================] - 39s 454ms/step - loss: 0.6950 - accuracy: 0.5642 - val_loss: 0.7832 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 13/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.5608epoch ended\n",
      "85/85 [==============================] - 47s 555ms/step - loss: 0.6738 - accuracy: 0.5607 - val_loss: 0.7979 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 14/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5603epoch ended\n",
      "85/85 [==============================] - 39s 461ms/step - loss: 0.6916 - accuracy: 0.5605 - val_loss: 0.7779 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 15/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.5481epoch ended\n",
      "85/85 [==============================] - 40s 472ms/step - loss: 0.7055 - accuracy: 0.5483 - val_loss: 1.0100 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 16/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.6001epoch ended\n",
      "85/85 [==============================] - 40s 460ms/step - loss: 0.6751 - accuracy: 0.6000 - val_loss: 1.0632 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 17/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6810 - accuracy: 0.5912epoch ended\n",
      "85/85 [==============================] - 25s 297ms/step - loss: 0.6810 - accuracy: 0.5913 - val_loss: 0.6926 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 18/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5623epoch ended\n",
      "85/85 [==============================] - 27s 318ms/step - loss: 0.6942 - accuracy: 0.5625 - val_loss: 1.0737 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 19/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.5932epoch ended\n",
      "85/85 [==============================] - 28s 334ms/step - loss: 0.6995 - accuracy: 0.5931 - val_loss: 0.7770 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 20/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.5494epoch ended\n",
      "85/85 [==============================] - 27s 322ms/step - loss: 0.6978 - accuracy: 0.5494 - val_loss: 0.8438 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 21/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5505epoch ended\n",
      "85/85 [==============================] - 34s 405ms/step - loss: 0.6961 - accuracy: 0.5503 - val_loss: 0.8328 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 22/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.5782epoch ended\n",
      "85/85 [==============================] - 34s 399ms/step - loss: 0.6653 - accuracy: 0.5783 - val_loss: 0.9911 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 23/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.5909epoch ended\n",
      "85/85 [==============================] - 37s 434ms/step - loss: 0.6524 - accuracy: 0.5907 - val_loss: 0.8888 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 24/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6770 - accuracy: 0.5817epoch ended\n",
      "85/85 [==============================] - 32s 374ms/step - loss: 0.6770 - accuracy: 0.5816 - val_loss: 1.2317 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 25/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6724 - accuracy: 0.5825epoch ended\n",
      "85/85 [==============================] - 62s 735ms/step - loss: 0.6723 - accuracy: 0.5828 - val_loss: 0.8041 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 26/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.5653epoch ended\n",
      "85/85 [==============================] - 39s 454ms/step - loss: 0.6844 - accuracy: 0.5657 - val_loss: 0.8937 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 27/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.6107epoch ended\n",
      "85/85 [==============================] - 31s 366ms/step - loss: 0.6707 - accuracy: 0.6107 - val_loss: 0.9332 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 28/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5512epoch ended\n",
      "85/85 [==============================] - 43s 499ms/step - loss: 0.6928 - accuracy: 0.5515 - val_loss: 0.9160 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 29/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.6058epoch ended\n",
      "85/85 [==============================] - 57s 673ms/step - loss: 0.6358 - accuracy: 0.6060 - val_loss: 0.7979 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 30/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.5886epoch ended\n",
      "85/85 [==============================] - 36s 418ms/step - loss: 0.6810 - accuracy: 0.5886 - val_loss: 0.7779 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 31/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.5628epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.6750 - accuracy: 0.5630 - val_loss: 0.9510 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 32/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.6322epoch ended\n",
      "85/85 [==============================] - 30s 352ms/step - loss: 0.6599 - accuracy: 0.6317 - val_loss: 0.8823 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 33/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6520 - accuracy: 0.6048epoch ended\n",
      "85/85 [==============================] - 26s 292ms/step - loss: 0.6521 - accuracy: 0.6048 - val_loss: 1.1796 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 34/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.6273epoch ended\n",
      "85/85 [==============================] - 39s 455ms/step - loss: 0.6508 - accuracy: 0.6272 - val_loss: 1.0135 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 35/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.5935epoch ended\n",
      "85/85 [==============================] - 36s 419ms/step - loss: 0.6638 - accuracy: 0.5933 - val_loss: 0.8840 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 36/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.5968epoch ended\n",
      "85/85 [==============================] - 31s 368ms/step - loss: 0.6827 - accuracy: 0.5967 - val_loss: 0.9874 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 37/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.6148epoch ended\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 0.6430 - accuracy: 0.6148 - val_loss: 0.9299 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 38/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6558 - accuracy: 0.6311epoch ended\n",
      "85/85 [==============================] - 27s 314ms/step - loss: 0.6558 - accuracy: 0.6310 - val_loss: 1.1322 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 39/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6615 - accuracy: 0.6031epoch ended\n",
      "85/85 [==============================] - 32s 380ms/step - loss: 0.6612 - accuracy: 0.6036 - val_loss: 1.2810 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 40/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.5992epoch ended\n",
      "85/85 [==============================] - 25s 293ms/step - loss: 0.6830 - accuracy: 0.5995 - val_loss: 1.0233 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 41/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.5924epoch ended\n",
      "85/85 [==============================] - 27s 314ms/step - loss: 0.6400 - accuracy: 0.5928 - val_loss: 1.0854 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 42/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.6123epoch ended\n",
      "85/85 [==============================] - 25s 295ms/step - loss: 0.6446 - accuracy: 0.6125 - val_loss: 0.9529 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 43/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.6241epoch ended\n",
      "85/85 [==============================] - 34s 406ms/step - loss: 0.6265 - accuracy: 0.6241 - val_loss: 1.0369 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 44/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.6412epoch ended\n",
      "85/85 [==============================] - 42s 493ms/step - loss: 0.6479 - accuracy: 0.6410 - val_loss: 2.4437 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 45/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.6372epoch ended\n",
      "85/85 [==============================] - 35s 410ms/step - loss: 0.6175 - accuracy: 0.6370 - val_loss: 1.1626 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 46/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.6360epoch ended\n",
      "85/85 [==============================] - 25s 296ms/step - loss: 0.6213 - accuracy: 0.6358 - val_loss: 1.5714 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 47/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.6205epoch ended\n",
      "85/85 [==============================] - 26s 301ms/step - loss: 0.6267 - accuracy: 0.6206 - val_loss: 1.0272 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 48/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0.6628epoch ended\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5758 - accuracy: 0.6624 - val_loss: 3.0482 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 49/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.5952epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.6073 - accuracy: 0.5955 - val_loss: 1.5440 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 50/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.6650epoch ended\n",
      "85/85 [==============================] - 36s 427ms/step - loss: 0.5975 - accuracy: 0.6648 - val_loss: 1.4190 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 51/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5760 - accuracy: 0.6550epoch ended\n",
      "85/85 [==============================] - 25s 292ms/step - loss: 0.5764 - accuracy: 0.6549 - val_loss: 1.4503 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 52/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6592 - accuracy: 0.6050epoch ended\n",
      "85/85 [==============================] - 28s 329ms/step - loss: 0.6588 - accuracy: 0.6056 - val_loss: 1.0916 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 53/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.7589epoch ended\n",
      "85/85 [==============================] - 33s 380ms/step - loss: 0.5104 - accuracy: 0.7578 - val_loss: 1.2581 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 54/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.6414epoch ended\n",
      "85/85 [==============================] - 31s 372ms/step - loss: 0.6337 - accuracy: 0.6417 - val_loss: 2.0865 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 55/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.7433epoch ended\n",
      "85/85 [==============================] - 36s 421ms/step - loss: 0.5302 - accuracy: 0.7428 - val_loss: 2.8803 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 56/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.6487epoch ended\n",
      "85/85 [==============================] - 31s 367ms/step - loss: 0.6301 - accuracy: 0.6492 - val_loss: 1.8893 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 57/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.7042epoch ended\n",
      "85/85 [==============================] - 25s 293ms/step - loss: 0.5673 - accuracy: 0.7043 - val_loss: 1.9153 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 58/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5821 - accuracy: 0.6638epoch ended\n",
      "85/85 [==============================] - 31s 366ms/step - loss: 0.5815 - accuracy: 0.6645 - val_loss: 2.9503 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 59/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.6503epoch ended\n",
      "85/85 [==============================] - 31s 369ms/step - loss: 0.6294 - accuracy: 0.6507 - val_loss: 2.4770 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 60/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.7551epoch ended\n",
      "85/85 [==============================] - 26s 300ms/step - loss: 0.4930 - accuracy: 0.7545 - val_loss: 1.3571 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 61/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.6382epoch ended\n",
      "85/85 [==============================] - 26s 305ms/step - loss: 0.6096 - accuracy: 0.6389 - val_loss: 1.7579 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 62/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.7290epoch ended\n",
      "85/85 [==============================] - 28s 331ms/step - loss: 0.4900 - accuracy: 0.7288 - val_loss: 1.9235 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 63/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5344 - accuracy: 0.7179epoch ended\n",
      "85/85 [==============================] - 37s 432ms/step - loss: 0.5345 - accuracy: 0.7177 - val_loss: 1.5956 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 64/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.7205epoch ended\n",
      "85/85 [==============================] - 33s 388ms/step - loss: 0.5477 - accuracy: 0.7205 - val_loss: 1.2196 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 65/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5165 - accuracy: 0.7029epoch ended\n",
      "85/85 [==============================] - 25s 284ms/step - loss: 0.5169 - accuracy: 0.7028 - val_loss: 1.6875 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 66/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.7146epoch ended\n",
      "85/85 [==============================] - 28s 327ms/step - loss: 0.5500 - accuracy: 0.7145 - val_loss: 2.1449 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 67/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4975 - accuracy: 0.7767epoch ended\n",
      "85/85 [==============================] - 29s 337ms/step - loss: 0.4971 - accuracy: 0.7768 - val_loss: 1.2667 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 68/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.7371epoch ended\n",
      "85/85 [==============================] - 27s 321ms/step - loss: 0.5310 - accuracy: 0.7372 - val_loss: 2.6292 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 69/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.7019epoch ended\n",
      "85/85 [==============================] - 29s 340ms/step - loss: 0.5706 - accuracy: 0.7023 - val_loss: 1.3251 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 70/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.7550epoch ended\n",
      "85/85 [==============================] - 26s 300ms/step - loss: 0.5009 - accuracy: 0.7553 - val_loss: 2.0766 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 71/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4986 - accuracy: 0.7673epoch ended\n",
      "85/85 [==============================] - 33s 377ms/step - loss: 0.4988 - accuracy: 0.7672 - val_loss: 2.2247 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 72/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.7773epoch ended\n",
      "85/85 [==============================] - 25s 298ms/step - loss: 0.4787 - accuracy: 0.7773 - val_loss: 2.7856 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 73/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.7778epoch ended\n",
      "85/85 [==============================] - 25s 293ms/step - loss: 0.5011 - accuracy: 0.7780 - val_loss: 1.7078 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 74/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8196epoch ended\n",
      "85/85 [==============================] - 25s 288ms/step - loss: 0.3824 - accuracy: 0.8196 - val_loss: 1.8625 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 75/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4375 - accuracy: 0.8115epoch ended\n",
      "85/85 [==============================] - 39s 457ms/step - loss: 0.4373 - accuracy: 0.8114 - val_loss: 2.2105 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 76/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8713epoch ended\n",
      "85/85 [==============================] - 26s 302ms/step - loss: 0.3221 - accuracy: 0.8711 - val_loss: 2.7938 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 77/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3243 - accuracy: 0.8833epoch ended\n",
      "85/85 [==============================] - 25s 296ms/step - loss: 0.3250 - accuracy: 0.8828 - val_loss: 2.8366 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 78/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.8026epoch ended\n",
      "85/85 [==============================] - 32s 381ms/step - loss: 0.4545 - accuracy: 0.8026 - val_loss: 1.4447 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 79/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.8496epoch ended\n",
      "85/85 [==============================] - 25s 288ms/step - loss: 0.3520 - accuracy: 0.8496 - val_loss: 1.1151 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 80/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.8612epoch ended\n",
      "85/85 [==============================] - 40s 473ms/step - loss: 0.3544 - accuracy: 0.8612 - val_loss: 1.2904 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 81/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.9059epoch ended\n",
      "85/85 [==============================] - 31s 361ms/step - loss: 0.2840 - accuracy: 0.9056 - val_loss: 1.4958 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 82/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9354epoch ended\n",
      "85/85 [==============================] - 24s 280ms/step - loss: 0.1964 - accuracy: 0.9349 - val_loss: 1.9139 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 83/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9188epoch ended\n",
      "85/85 [==============================] - 34s 395ms/step - loss: 0.2244 - accuracy: 0.9184 - val_loss: 1.5135 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 84/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2970 - accuracy: 0.8813epoch ended\n",
      "85/85 [==============================] - 25s 290ms/step - loss: 0.2969 - accuracy: 0.8813 - val_loss: 0.9556 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 85/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.8906epoch ended\n",
      "85/85 [==============================] - 32s 375ms/step - loss: 0.2364 - accuracy: 0.8907 - val_loss: 1.7597 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 86/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.8895epoch ended\n",
      "85/85 [==============================] - 25s 297ms/step - loss: 0.2430 - accuracy: 0.8893 - val_loss: 1.9095 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 87/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9074epoch ended\n",
      "85/85 [==============================] - 34s 403ms/step - loss: 0.2416 - accuracy: 0.9076 - val_loss: 1.6554 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 88/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9101epoch ended\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 0.2367 - accuracy: 0.9102 - val_loss: 1.7623 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 89/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1515 - accuracy: 0.9522epoch ended\n",
      "85/85 [==============================] - 28s 325ms/step - loss: 0.1526 - accuracy: 0.9517 - val_loss: 1.2118 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 90/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9364epoch ended\n",
      "85/85 [==============================] - 32s 377ms/step - loss: 0.1544 - accuracy: 0.9363 - val_loss: 1.2331 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 91/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3127 - accuracy: 0.8784epoch ended\n",
      "85/85 [==============================] - 29s 328ms/step - loss: 0.3124 - accuracy: 0.8784 - val_loss: 1.5651 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 92/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9527epoch ended\n",
      "85/85 [==============================] - 46s 545ms/step - loss: 0.1434 - accuracy: 0.9527 - val_loss: 1.7443 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 93/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1516 - accuracy: 0.9483epoch ended\n",
      "85/85 [==============================] - 26s 294ms/step - loss: 0.1518 - accuracy: 0.9481 - val_loss: 1.3657 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 94/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9412epoch ended\n",
      "85/85 [==============================] - 39s 465ms/step - loss: 0.1787 - accuracy: 0.9411 - val_loss: 1.4342 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 95/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.9049epoch ended\n",
      "85/85 [==============================] - 34s 406ms/step - loss: 0.2250 - accuracy: 0.9053 - val_loss: 1.1781 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 96/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9621epoch ended\n",
      "85/85 [==============================] - 34s 399ms/step - loss: 0.1207 - accuracy: 0.9621 - val_loss: 1.4681 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 97/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.9503epoch ended\n",
      "85/85 [==============================] - 26s 302ms/step - loss: 0.1745 - accuracy: 0.9499 - val_loss: 1.6920 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 98/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9243epoch ended\n",
      "85/85 [==============================] - 25s 291ms/step - loss: 0.1913 - accuracy: 0.9240 - val_loss: 2.0627 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 99/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9822epoch ended\n",
      "85/85 [==============================] - 26s 312ms/step - loss: 0.0778 - accuracy: 0.9821 - val_loss: 1.7842 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 100/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9839epoch ended\n",
      "85/85 [==============================] - 25s 298ms/step - loss: 0.0718 - accuracy: 0.9838 - val_loss: 1.6329 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 101/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.9520epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 0.1706 - accuracy: 0.9522 - val_loss: 1.4933 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 102/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9856epoch ended\n",
      "85/85 [==============================] - 34s 397ms/step - loss: 0.0588 - accuracy: 0.9855 - val_loss: 2.0638 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 103/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9602epoch ended\n",
      "85/85 [==============================] - 26s 298ms/step - loss: 0.1171 - accuracy: 0.9603 - val_loss: 1.3262 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 104/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9566epoch ended\n",
      "85/85 [==============================] - 26s 296ms/step - loss: 0.0950 - accuracy: 0.9564 - val_loss: 1.0933 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 105/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.8793epoch ended\n",
      "85/85 [==============================] - 25s 298ms/step - loss: 0.3260 - accuracy: 0.8798 - val_loss: 0.9837 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 106/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9875epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.0482 - accuracy: 0.9874 - val_loss: 1.1168 - val_accuracy: 0.4340\n",
      "epoch ended\n",
      "Epoch 107/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9761epoch ended\n",
      "85/85 [==============================] - 35s 415ms/step - loss: 0.0863 - accuracy: 0.9760 - val_loss: 1.4446 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 108/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1617 - accuracy: 0.9396epoch ended\n",
      "85/85 [==============================] - 33s 389ms/step - loss: 0.1613 - accuracy: 0.9398 - val_loss: 1.3868 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 109/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9654epoch ended\n",
      "85/85 [==============================] - 29s 340ms/step - loss: 0.1116 - accuracy: 0.9652 - val_loss: 1.4391 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 110/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9547epoch ended\n",
      "85/85 [==============================] - 26s 302ms/step - loss: 0.1234 - accuracy: 0.9548 - val_loss: 1.3939 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 111/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.9496epoch ended\n",
      "85/85 [==============================] - 26s 307ms/step - loss: 0.1310 - accuracy: 0.9498 - val_loss: 1.1514 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 112/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9940epoch ended\n",
      "85/85 [==============================] - 28s 328ms/step - loss: 0.0394 - accuracy: 0.9939 - val_loss: 1.2050 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 113/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9621epoch ended\n",
      "85/85 [==============================] - 29s 328ms/step - loss: 0.1250 - accuracy: 0.9618 - val_loss: 1.7184 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 114/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9474epoch ended\n",
      "85/85 [==============================] - 31s 356ms/step - loss: 0.1372 - accuracy: 0.9474 - val_loss: 1.3059 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 115/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9801epoch ended\n",
      "85/85 [==============================] - 34s 398ms/step - loss: 0.0491 - accuracy: 0.9801 - val_loss: 1.5838 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 116/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9776epoch ended\n",
      "85/85 [==============================] - 29s 343ms/step - loss: 0.0771 - accuracy: 0.9776 - val_loss: 1.5015 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 117/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9559epoch ended\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 0.1069 - accuracy: 0.9560 - val_loss: 1.3370 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 118/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9932epoch ended\n",
      "85/85 [==============================] - 26s 302ms/step - loss: 0.0382 - accuracy: 0.9932 - val_loss: 1.1376 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 119/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9819epoch ended\n",
      "85/85 [==============================] - 31s 369ms/step - loss: 0.0564 - accuracy: 0.9818 - val_loss: 1.1686 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 120/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9551epoch ended\n",
      "85/85 [==============================] - 25s 292ms/step - loss: 0.1451 - accuracy: 0.9551 - val_loss: 1.0506 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 121/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9734epoch ended\n",
      "85/85 [==============================] - 26s 303ms/step - loss: 0.0690 - accuracy: 0.9735 - val_loss: 1.0691 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 122/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9972epoch ended\n",
      "85/85 [==============================] - 27s 316ms/step - loss: 0.0225 - accuracy: 0.9972 - val_loss: 1.2403 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 123/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2902 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 124/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9901epoch ended\n",
      "85/85 [==============================] - 25s 292ms/step - loss: 0.0157 - accuracy: 0.9901 - val_loss: 1.1907 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 125/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9991epoch ended\n",
      "85/85 [==============================] - 26s 301ms/step - loss: 0.0074 - accuracy: 0.9991 - val_loss: 1.4428 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 126/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 299ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4519 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 127/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 42s 499ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2588 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 128/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9671epoch ended\n",
      "85/85 [==============================] - 32s 372ms/step - loss: 0.0799 - accuracy: 0.9671 - val_loss: 1.8015 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 129/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9698epoch ended\n",
      "85/85 [==============================] - 27s 309ms/step - loss: 0.0704 - accuracy: 0.9698 - val_loss: 1.2605 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 130/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.9466epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 0.1663 - accuracy: 0.9467 - val_loss: 1.2275 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 131/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9785epoch ended\n",
      "85/85 [==============================] - 26s 311ms/step - loss: 0.0574 - accuracy: 0.9785 - val_loss: 1.1521 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 132/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9893epoch ended\n",
      "85/85 [==============================] - 27s 307ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 1.1787 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 133/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9854epoch ended\n",
      "85/85 [==============================] - 25s 290ms/step - loss: 0.0354 - accuracy: 0.9854 - val_loss: 1.2787 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 134/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9986epoch ended\n",
      "85/85 [==============================] - 39s 461ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 1.0416 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 135/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9776epoch ended\n",
      "85/85 [==============================] - 25s 291ms/step - loss: 0.0545 - accuracy: 0.9776 - val_loss: 1.2098 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 136/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9994epoch ended\n",
      "85/85 [==============================] - 25s 295ms/step - loss: 0.0116 - accuracy: 0.9994 - val_loss: 1.4943 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 137/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9949epoch ended\n",
      "85/85 [==============================] - 26s 302ms/step - loss: 0.0269 - accuracy: 0.9948 - val_loss: 1.3814 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 138/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9843epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 0.0396 - accuracy: 0.9844 - val_loss: 1.7956 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 139/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9868epoch ended\n",
      "85/85 [==============================] - 37s 433ms/step - loss: 0.0331 - accuracy: 0.9868 - val_loss: 1.7501 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 140/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9893epoch ended\n",
      "85/85 [==============================] - 28s 321ms/step - loss: 0.0259 - accuracy: 0.9893 - val_loss: 1.7444 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 141/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9860epoch ended\n",
      "85/85 [==============================] - 31s 370ms/step - loss: 0.0634 - accuracy: 0.9861 - val_loss: 1.4089 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 142/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9786epoch ended\n",
      "85/85 [==============================] - 42s 493ms/step - loss: 0.0413 - accuracy: 0.9787 - val_loss: 1.7654 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 143/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9965epoch ended\n",
      "85/85 [==============================] - 27s 314ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.3037 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 144/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9960epoch ended\n",
      "85/85 [==============================] - 26s 297ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.9513 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 145/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9948epoch ended\n",
      "85/85 [==============================] - 36s 420ms/step - loss: 0.0273 - accuracy: 0.9947 - val_loss: 0.9046 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 146/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9915epoch ended\n",
      "85/85 [==============================] - 25s 299ms/step - loss: 0.0185 - accuracy: 0.9915 - val_loss: 1.2347 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 147/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9963epoch ended\n",
      "85/85 [==============================] - 24s 280ms/step - loss: 0.0181 - accuracy: 0.9963 - val_loss: 0.9820 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 148/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9999epoch ended\n",
      "85/85 [==============================] - 26s 304ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 1.2938 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 149/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9906epoch ended\n",
      "85/85 [==============================] - 25s 292ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 1.2764 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 150/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9833epoch ended\n",
      "85/85 [==============================] - 28s 321ms/step - loss: 0.0593 - accuracy: 0.9830 - val_loss: 1.0975 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 151/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9268epoch ended\n",
      "85/85 [==============================] - 26s 311ms/step - loss: 0.2006 - accuracy: 0.9270 - val_loss: 1.1274 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 152/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9888epoch ended\n",
      "85/85 [==============================] - 36s 428ms/step - loss: 0.0598 - accuracy: 0.9887 - val_loss: 1.1272 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 153/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9829epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 0.0391 - accuracy: 0.9828 - val_loss: 1.7475 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 154/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9793epoch ended\n",
      "85/85 [==============================] - 26s 307ms/step - loss: 0.0726 - accuracy: 0.9794 - val_loss: 0.9600 - val_accuracy: 0.4528\n",
      "epoch ended\n",
      "Epoch 155/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9838epoch ended\n",
      "85/85 [==============================] - 26s 302ms/step - loss: 0.0215 - accuracy: 0.9839 - val_loss: 1.0465 - val_accuracy: 0.4151\n",
      "epoch ended\n",
      "Epoch 156/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9972epoch ended\n",
      "85/85 [==============================] - 25s 290ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 1.1108 - val_accuracy: 0.4151\n",
      "epoch ended\n",
      "Epoch 157/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9969epoch ended\n",
      "85/85 [==============================] - 25s 298ms/step - loss: 0.0225 - accuracy: 0.9969 - val_loss: 1.2036 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 158/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 303ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1695 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 159/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 29s 342ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2171 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 160/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9951epoch ended\n",
      "85/85 [==============================] - 24s 286ms/step - loss: 0.0079 - accuracy: 0.9951 - val_loss: 1.0592 - val_accuracy: 0.4528\n",
      "epoch ended\n",
      "Epoch 161/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 290ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0864 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 162/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 304ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 163/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 285ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0981 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 164/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 28s 330ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 165/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 300ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 166/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9953epoch ended\n",
      "85/85 [==============================] - 26s 294ms/step - loss: 0.0062 - accuracy: 0.9953 - val_loss: 1.1770 - val_accuracy: 0.4340\n",
      "epoch ended\n",
      "Epoch 167/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 38s 443ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 168/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9981epoch ended\n",
      "85/85 [==============================] - 24s 287ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.1507 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 169/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 30s 350ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 170/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9995epoch ended\n",
      "85/85 [==============================] - 38s 446ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 1.6045 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 171/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9962epoch ended\n",
      "85/85 [==============================] - 26s 303ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.7219 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 172/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9951epoch ended\n",
      "85/85 [==============================] - 26s 310ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 1.3102 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 173/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9582epoch ended\n",
      "85/85 [==============================] - 39s 464ms/step - loss: 0.1580 - accuracy: 0.9580 - val_loss: 1.6550 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 174/300\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 0.9699epoch ended\n",
      "85/85 [==============================] - 27s 315ms/step - loss: 0.0992 - accuracy: 0.9698 - val_loss: 1.7452 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 175/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9837epoch ended\n",
      "85/85 [==============================] - 27s 322ms/step - loss: 0.0635 - accuracy: 0.9836 - val_loss: 1.4536 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 176/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9902epoch ended\n",
      "85/85 [==============================] - 38s 444ms/step - loss: 0.0375 - accuracy: 0.9901 - val_loss: 1.1375 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 177/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9885epoch ended\n",
      "85/85 [==============================] - 25s 296ms/step - loss: 0.0378 - accuracy: 0.9886 - val_loss: 0.9874 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 178/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9875epoch ended\n",
      "85/85 [==============================] - 25s 296ms/step - loss: 0.0291 - accuracy: 0.9875 - val_loss: 0.8735 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 179/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9863epoch ended\n",
      "85/85 [==============================] - 25s 288ms/step - loss: 0.0364 - accuracy: 0.9862 - val_loss: 1.0218 - val_accuracy: 0.4528\n",
      "epoch ended\n",
      "Epoch 180/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9886epoch ended\n",
      "85/85 [==============================] - 32s 373ms/step - loss: 0.0293 - accuracy: 0.9886 - val_loss: 1.1416 - val_accuracy: 0.4528\n",
      "epoch ended\n",
      "Epoch 181/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9974epoch ended\n",
      "85/85 [==============================] - 34s 401ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 1.0972 - val_accuracy: 0.4340\n",
      "epoch ended\n",
      "Epoch 182/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 296ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 183/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 281ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9946 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 184/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9992epoch ended\n",
      "85/85 [==============================] - 25s 297ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 1.1593 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 185/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 319ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 186/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 44s 525ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.1108 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 187/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 284ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0548 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 188/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9987epoch ended\n",
      "85/85 [==============================] - 26s 304ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.5275 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 189/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9990epoch ended\n",
      "85/85 [==============================] - 25s 287ms/step - loss: 0.0081 - accuracy: 0.9990 - val_loss: 1.3558 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 190/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9780epoch ended\n",
      "85/85 [==============================] - 30s 353ms/step - loss: 0.0368 - accuracy: 0.9781 - val_loss: 1.4955 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 191/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9996epoch ended\n",
      "85/85 [==============================] - 25s 293ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 1.5339 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 192/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9968epoch ended\n",
      "85/85 [==============================] - 24s 281ms/step - loss: 0.0055 - accuracy: 0.9968 - val_loss: 1.3796 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 193/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 305ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3551 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 194/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.1335e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 32s 375ms/step - loss: 3.1501e-04 - accuracy: 1.0000 - val_loss: 1.3518 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 195/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 9.1754e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 309ms/step - loss: 9.1412e-04 - accuracy: 1.0000 - val_loss: 1.4558 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 196/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9826epoch ended\n",
      "85/85 [==============================] - 25s 297ms/step - loss: 0.0422 - accuracy: 0.9826 - val_loss: 2.3597 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 197/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9541epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.1750 - accuracy: 0.9543 - val_loss: 1.7668 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 198/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.9284epoch ended\n",
      "85/85 [==============================] - 27s 316ms/step - loss: 0.2093 - accuracy: 0.9284 - val_loss: 2.6341 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 199/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9812epoch ended\n",
      "85/85 [==============================] - 25s 291ms/step - loss: 0.0367 - accuracy: 0.9812 - val_loss: 1.9947 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 200/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 32s 374ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.9160 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 201/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9932epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.0117 - accuracy: 0.9932 - val_loss: 1.6255 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 202/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9984epoch ended\n",
      "85/85 [==============================] - 30s 357ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 1.8797 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 203/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9974epoch ended\n",
      "85/85 [==============================] - 27s 317ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 1.7951 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 204/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9977epoch ended\n",
      "85/85 [==============================] - 29s 345ms/step - loss: 0.0139 - accuracy: 0.9977 - val_loss: 1.0275 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 205/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9910epoch ended\n",
      "85/85 [==============================] - 27s 310ms/step - loss: 0.0364 - accuracy: 0.9911 - val_loss: 0.9551 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 206/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9906epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.0180 - accuracy: 0.9906 - val_loss: 1.5180 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 207/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9995epoch ended\n",
      "85/85 [==============================] - 26s 302ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 1.3859 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 208/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 316ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.5233 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 209/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9993epoch ended\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 1.1277 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 210/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9972epoch ended\n",
      "85/85 [==============================] - 27s 319ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.1917 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 211/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9888epoch ended\n",
      "85/85 [==============================] - 24s 286ms/step - loss: 0.0501 - accuracy: 0.9887 - val_loss: 1.0311 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 212/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9881epoch ended\n",
      "85/85 [==============================] - 31s 364ms/step - loss: 0.0413 - accuracy: 0.9881 - val_loss: 1.0996 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 213/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9995epoch ended\n",
      "85/85 [==============================] - 27s 313ms/step - loss: 0.0218 - accuracy: 0.9994 - val_loss: 1.0473 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 214/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9643epoch ended\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 0.1064 - accuracy: 0.9644 - val_loss: 1.9486 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 215/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9831epoch ended\n",
      "85/85 [==============================] - 27s 313ms/step - loss: 0.0412 - accuracy: 0.9832 - val_loss: 1.7010 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 216/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9975epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.3795 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 217/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9979epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 1.3731 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 218/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 28s 325ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3752 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 219/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9904epoch ended\n",
      "85/85 [==============================] - 25s 295ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 1.5623 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 220/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9974epoch ended\n",
      "85/85 [==============================] - 26s 308ms/step - loss: 0.0045 - accuracy: 0.9974 - val_loss: 1.1907 - val_accuracy: 0.6038\n",
      "epoch ended\n",
      "Epoch 221/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 1.2594 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 222/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 278ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1879 - val_accuracy: 0.5849\n",
      "epoch ended\n",
      "Epoch 223/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996epoch ended\n",
      "85/85 [==============================] - 27s 315ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 1.3466 - val_accuracy: 0.5849\n",
      "epoch ended\n",
      "Epoch 224/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 285ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2932 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 225/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0835 - val_accuracy: 0.6226\n",
      "epoch ended\n",
      "Epoch 226/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.0026e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 295ms/step - loss: 7.0147e-04 - accuracy: 1.0000 - val_loss: 1.3369 - val_accuracy: 0.5849\n",
      "epoch ended\n",
      "Epoch 227/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 312ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4146 - val_accuracy: 0.5849\n",
      "epoch ended\n",
      "Epoch 228/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 309ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4907 - val_accuracy: 0.5849\n",
      "epoch ended\n",
      "Epoch 229/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9959epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 1.1744 - val_accuracy: 0.6226\n",
      "epoch ended\n",
      "Epoch 230/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9796epoch ended\n",
      "85/85 [==============================] - 37s 437ms/step - loss: 0.0655 - accuracy: 0.9796 - val_loss: 1.7441 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 231/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9674epoch ended\n",
      "85/85 [==============================] - 25s 299ms/step - loss: 0.1234 - accuracy: 0.9675 - val_loss: 1.6335 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 232/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9996epoch ended\n",
      "85/85 [==============================] - 25s 292ms/step - loss: 0.0157 - accuracy: 0.9996 - val_loss: 1.6159 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 233/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9993epoch ended\n",
      "85/85 [==============================] - 27s 312ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 1.6956 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 234/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9990epoch ended\n",
      "85/85 [==============================] - 33s 383ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 1.8073 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 235/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9916epoch ended\n",
      "85/85 [==============================] - 25s 295ms/step - loss: 0.0171 - accuracy: 0.9915 - val_loss: 1.3890 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 236/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9512epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.1055 - accuracy: 0.9514 - val_loss: 1.2660 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 237/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9926epoch ended\n",
      "85/85 [==============================] - 28s 330ms/step - loss: 0.0299 - accuracy: 0.9925 - val_loss: 1.8062 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 238/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9713epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 0.0900 - accuracy: 0.9714 - val_loss: 1.3072 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 239/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9925epoch ended\n",
      "85/85 [==============================] - 25s 284ms/step - loss: 0.0159 - accuracy: 0.9925 - val_loss: 1.2172 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 240/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 291ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3468 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 241/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 302ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4390 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 242/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 286ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4221 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 243/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 306ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4211 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 244/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 292ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4323 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 245/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2494 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 246/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.4328e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 310ms/step - loss: 5.4350e-04 - accuracy: 1.0000 - val_loss: 1.4047 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 247/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.8182e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 4.8299e-04 - accuracy: 1.0000 - val_loss: 1.4445 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 248/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 8.7353e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 285ms/step - loss: 8.7415e-04 - accuracy: 1.0000 - val_loss: 1.4796 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 249/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 6.9621e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 312ms/step - loss: 6.9638e-04 - accuracy: 1.0000 - val_loss: 1.5059 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 250/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.2004e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 297ms/step - loss: 7.2022e-04 - accuracy: 1.0000 - val_loss: 1.4424 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 251/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.4317e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 320ms/step - loss: 5.4183e-04 - accuracy: 1.0000 - val_loss: 1.3751 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 252/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.0610e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 290ms/step - loss: 3.0610e-04 - accuracy: 1.0000 - val_loss: 1.4774 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 253/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.3337e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 296ms/step - loss: 3.3606e-04 - accuracy: 1.0000 - val_loss: 1.4839 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 254/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 311ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4526 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 255/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.2024e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 3.1996e-04 - accuracy: 1.0000 - val_loss: 1.5295 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 256/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999epoch ended\n",
      "85/85 [==============================] - 26s 305ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 1.2254 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 257/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9751epoch ended\n",
      "85/85 [==============================] - 27s 320ms/step - loss: 0.0676 - accuracy: 0.9750 - val_loss: 1.5091 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 258/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9179epoch ended\n",
      "85/85 [==============================] - 25s 295ms/step - loss: 0.1800 - accuracy: 0.9183 - val_loss: 1.5796 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 259/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9920epoch ended\n",
      "85/85 [==============================] - 27s 322ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 1.1905 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 260/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 296ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.1768 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 261/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 290ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 262/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 32s 372ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2185 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 263/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 9.1496e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 290ms/step - loss: 9.2206e-04 - accuracy: 1.0000 - val_loss: 1.3166 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 264/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 8.9487e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 303ms/step - loss: 8.9371e-04 - accuracy: 1.0000 - val_loss: 1.2121 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 265/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 295ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3032 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 266/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.4797e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 43s 512ms/step - loss: 4.4939e-04 - accuracy: 1.0000 - val_loss: 1.3294 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 267/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 6.5561e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 296ms/step - loss: 6.5671e-04 - accuracy: 1.0000 - val_loss: 1.3918 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 268/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.7440e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 291ms/step - loss: 3.7740e-04 - accuracy: 1.0000 - val_loss: 1.3461 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 269/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995epoch ended\n",
      "85/85 [==============================] - 28s 316ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 1.6132 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 270/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9946epoch ended\n",
      "85/85 [==============================] - 26s 299ms/step - loss: 0.0125 - accuracy: 0.9946 - val_loss: 1.4688 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 271/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 37s 432ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6479 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 272/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 300ms/step - loss: 9.9941e-04 - accuracy: 1.0000 - val_loss: 1.4577 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 273/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.9089e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 287ms/step - loss: 5.9327e-04 - accuracy: 1.0000 - val_loss: 1.5897 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 274/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.4120e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 317ms/step - loss: 5.4099e-04 - accuracy: 1.0000 - val_loss: 1.3829 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 275/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.4406e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 288ms/step - loss: 3.4512e-04 - accuracy: 1.0000 - val_loss: 1.7292 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 276/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.4725e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 23s 275ms/step - loss: 2.4879e-04 - accuracy: 1.0000 - val_loss: 1.7740 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 277/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.5153e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 28s 329ms/step - loss: 2.5343e-04 - accuracy: 1.0000 - val_loss: 1.7300 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 278/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.3837e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 299ms/step - loss: 2.3763e-04 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 279/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.4723e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 305ms/step - loss: 1.5889e-04 - accuracy: 1.0000 - val_loss: 1.5101 - val_accuracy: 0.5660\n",
      "epoch ended\n",
      "Epoch 280/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.7725e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 304ms/step - loss: 4.8423e-04 - accuracy: 1.0000 - val_loss: 1.6385 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 281/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.7403e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 285ms/step - loss: 5.7561e-04 - accuracy: 1.0000 - val_loss: 1.5789 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 282/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.6258e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 28s 326ms/step - loss: 1.6232e-04 - accuracy: 1.0000 - val_loss: 1.5439 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 283/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.7463e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 293ms/step - loss: 1.7522e-04 - accuracy: 1.0000 - val_loss: 1.6401 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 284/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.4418e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 1.4504e-04 - accuracy: 1.0000 - val_loss: 1.4441 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 285/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.7183e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 308ms/step - loss: 1.7229e-04 - accuracy: 1.0000 - val_loss: 1.6282 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 286/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.0087e-05 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 282ms/step - loss: 7.0593e-05 - accuracy: 1.0000 - val_loss: 1.8019 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 287/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.6920e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 281ms/step - loss: 4.7403e-04 - accuracy: 1.0000 - val_loss: 1.6240 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 288/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.7912e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 309ms/step - loss: 1.7995e-04 - accuracy: 1.0000 - val_loss: 1.7616 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 289/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.2796e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 293ms/step - loss: 1.2901e-04 - accuracy: 1.0000 - val_loss: 1.5583 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 290/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.5673e-05 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 26s 304ms/step - loss: 4.5860e-05 - accuracy: 1.0000 - val_loss: 1.6225 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 291/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5677e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 297ms/step - loss: 1.5691e-04 - accuracy: 1.0000 - val_loss: 1.6917 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 292/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 8.7253e-05 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 282ms/step - loss: 8.7229e-05 - accuracy: 1.0000 - val_loss: 1.4251 - val_accuracy: 0.5472\n",
      "epoch ended\n",
      "Epoch 293/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0548e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 316ms/step - loss: 1.0563e-04 - accuracy: 1.0000 - val_loss: 1.5981 - val_accuracy: 0.5094\n",
      "epoch ended\n",
      "Epoch 294/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.3570e-05 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 289ms/step - loss: 7.4974e-05 - accuracy: 1.0000 - val_loss: 1.4258 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 295/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.9838e-05 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 282ms/step - loss: 7.9878e-05 - accuracy: 1.0000 - val_loss: 1.7293 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 296/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 8.7348e-05 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 27s 317ms/step - loss: 8.7322e-05 - accuracy: 1.0000 - val_loss: 1.7508 - val_accuracy: 0.4717\n",
      "epoch ended\n",
      "Epoch 297/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 9.5143e-05 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 24s 286ms/step - loss: 9.5208e-05 - accuracy: 1.0000 - val_loss: 1.7699 - val_accuracy: 0.4906\n",
      "epoch ended\n",
      "Epoch 298/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.7281e-04 - accuracy: 1.0000epoch ended\n",
      "85/85 [==============================] - 25s 294ms/step - loss: 2.7431e-04 - accuracy: 1.0000 - val_loss: 1.8796 - val_accuracy: 0.4528\n",
      "epoch ended\n",
      "Epoch 299/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9956epoch ended\n",
      "85/85 [==============================] - 27s 312ms/step - loss: 0.0200 - accuracy: 0.9955 - val_loss: 1.7980 - val_accuracy: 0.5283\n",
      "epoch ended\n",
      "Epoch 300/300\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.8704epoch ended\n",
      "85/85 [==============================] - 24s 285ms/step - loss: 0.5212 - accuracy: 0.8706 - val_loss: 3.0596 - val_accuracy: 0.5283\n",
      "epoch ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7700df2f90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=len(train_datagen)//5,\n",
    "    validation_data=test_datagen,\\\n",
    "    validation_steps=len(test_datagen)-2,\n",
    "    epochs=300,\n",
    "    verbose=1,\n",
    "    callbacks = [checkpoint_cb,summary]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T19:44:25.160507Z",
     "iopub.status.busy": "2021-10-06T19:44:25.159609Z",
     "iopub.status.idle": "2021-10-06T19:44:25.782975Z",
     "shell.execute_reply": "2021-10-06T19:44:25.782333Z"
    },
    "papermill": {
     "duration": 7.628899,
     "end_time": "2021-10-06T19:44:25.783107",
     "exception": false,
     "start_time": "2021-10-06T19:44:18.154208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model.save('best_50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T19:44:40.701050Z",
     "iopub.status.busy": "2021-10-06T19:44:40.700078Z",
     "iopub.status.idle": "2021-10-06T19:44:40.704901Z",
     "shell.execute_reply": "2021-10-06T19:44:40.704470Z"
    },
    "papermill": {
     "duration": 7.4734,
     "end_time": "2021-10-06T19:44:40.705022",
     "exception": false,
     "start_time": "2021-10-06T19:44:33.231622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch ended\n"
     ]
    }
   ],
   "source": [
    "train_datagen = DataGenerator(train_slices_list,train_folders_list,train_label_list,batch_size=5,height=224,width=224,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-06T19:44:55.798930Z",
     "iopub.status.busy": "2021-10-06T19:44:55.798291Z",
     "iopub.status.idle": "2021-10-06T19:45:20.726921Z",
     "shell.execute_reply": "2021-10-06T19:45:20.727388Z"
    },
    "papermill": {
     "duration": 32.148581,
     "end_time": "2021-10-06T19:45:20.727576",
     "exception": false,
     "start_time": "2021-10-06T19:44:48.578995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_cnt = 0\n",
    "all_cnt = 0\n",
    "for i in range(len(train_datagen)//5):\n",
    "    x,y = train_datagen[i]\n",
    "    y_pred = new_model.predict(x)\n",
    "    output = np.argmax(np.round_(y_pred,1),axis=1)==np.argmax(y,1)\n",
    "    true_cnt += sum(output)\n",
    "    all_cnt += len(output)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "papermill": {
     "duration": 6.977126,
     "end_time": "2021-10-06T19:45:34.880292",
     "exception": false,
     "start_time": "2021-10-06T19:45:27.903166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "true_cnt/all_cnt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9832.069366,
   "end_time": "2021-10-06T19:45:43.832025",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-06T17:01:51.762659",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
